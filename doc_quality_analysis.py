#!/usr/bin/env python3
"""
æ–‡æ¡£è´¨é‡æ·±åº¦åˆ†æå·¥å…·
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple
import re


class DocQualityAnalyzer:
    """æ–‡æ¡£è´¨é‡åˆ†æå™¨"""
    
    def __init__(self, results_file: str):
        with open(results_file, 'r', encoding='utf-8') as f:
            self.results = json.load(f)
    
    def analyze_tool_documentation(self) -> Dict:
        """åˆ†æå·¥å…·æ–‡æ¡£çš„è´¨é‡"""
        tool_files = [
            'kimi_cli/tools/bash/__init__.py',
            'kimi_cli/tools/file/read.py',
            'kimi_cli/tools/file/write.py',
            'kimi_cli/tools/file/grep.py',
            'kimi_cli/tools/web/search.py',
            'kimi_cli/tools/web/fetch.py',
            'kimi_cli/tools/task/__init__.py',
            'kimi_cli/tools/dmail/__init__.py',
            'kimi_cli/tools/think/__init__.py',
            'kimi_cli/tools/todo/__init__.py'
        ]
        
        tool_analysis = {
            'well_documented': [],
            'poorly_documented': [],
            'missing_docs': [],
            'descriptions': {}
        }
        
        for file_result in self.results['detailed_results']:
            file_path = file_result['file_path']
            
            if file_path in tool_files:
                # æ£€æŸ¥å·¥å…·ç±»çš„æ–‡æ¡£
                if file_result['classes']:
                    for cls in file_result['classes']:
                        if cls['has_docstring']:
                            tool_analysis['well_documented'].append(f"{file_path}::{cls['name']}")
                        else:
                            tool_analysis['poorly_documented'].append(f"{file_path}::{cls['name']}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æè¿°æ–‡ä»¶
                desc_file = self._check_description_file(file_path)
                if desc_file:
                    tool_analysis['descriptions'][file_path] = desc_file
        
        return tool_analysis
    
    def _check_description_file(self, tool_file: str) -> str:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦æœ‰æè¿°æ–‡ä»¶"""
        base_path = tool_file.replace('kimi_cli/', 'src/kimi_cli/').replace('/__init__.py', '')
        base_path = base_path.replace('.py', '')
        
        possible_files = [
            f"{base_path}.md",
            f"{base_path}/README.md",
            f"{base_path}/description.md"
        ]
        
        for file_path in possible_files:
            if Path(file_path).exists():
                return file_path
        
        return ""
    
    def analyze_core_modules(self) -> Dict:
        """åˆ†ææ ¸å¿ƒæ¨¡å—çš„æ–‡æ¡£è´¨é‡"""
        core_files = [
            'kimi_cli/soul/kimisoul.py',
            'kimi_cli/soul/agent.py',
            'kimi_cli/soul/context.py',
            'kimi_cli/llm.py',
            'kimi_cli/config.py',
            'kimi_cli/app.py'
        ]
        
        core_analysis = {
            'documentation_level': {},
            'complex_functions': [],
            'public_apis': []
        }
        
        for file_result in self.results['detailed_results']:
            file_path = file_result['file_path']
            
            if file_path in core_files:
                # è®¡ç®—æ–‡æ¡£åŒ–æ°´å¹³
                total_items = (len(file_result.get('functions', [])) + 
                             len(file_result.get('classes', [])))
                documented_items = sum(1 for f in file_result.get('functions', []) if f['has_docstring']) + \
                                 sum(1 for c in file_result.get('classes', []) if c['has_docstring'])
                
                if total_items > 0:
                    doc_level = (documented_items / total_items) * 100
                    core_analysis['documentation_level'][file_path] = {
                        'percentage': doc_level,
                        'documented': documented_items,
                        'total': total_items
                    }
                
                # è¯†åˆ«å¤æ‚å‡½æ•°ï¼ˆå‚æ•°è¾ƒå¤šæˆ–é€»è¾‘å¤æ‚ï¼‰
                for func in file_result.get('functions', []):
                    if len(func.get('params', [])) > 3:  # å‚æ•°è¶…è¿‡3ä¸ª
                        core_analysis['complex_functions'].append({
                            'file': file_path,
                            'function': func['name'],
                            'params': len(func['params']),
                            'has_doc': func['has_docstring']
                        })
        
        return core_analysis
    
    def check_documentation_consistency(self) -> List[str]:
        """æ£€æŸ¥æ–‡æ¡£æ ¼å¼ä¸€è‡´æ€§"""
        issues = []
        
        # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼
        format_patterns = {
            'google': r'Args:\s*\n.*?Returns:\s*\n',
            'numpy': r'Parameters\s*\n.*?----------.*?Returns\s*\n.*?----------',
            'sphinx': r':param.*?\n.*?:(return|returns):'
        }
        
        documented_items = []
        
        for file_result in self.results['detailed_results']:
            for func in file_result.get('functions', []):
                if func['has_docstring']:
                    documented_items.append({
                        'type': 'function',
                        'name': func['name'],
                        'file': file_result['file_path']
                    })
            
            for cls in file_result.get('classes', []):
                if cls['has_docstring']:
                    documented_items.append({
                        'type': 'class', 
                        'name': cls['name'],
                        'file': file_result['file_path']
                    })
        
        issues.append(f"å‘ç° {len(documented_items)} ä¸ªæœ‰æ–‡æ¡£çš„é¡¹ç›®ï¼Œä½†æ ¼å¼ä¸ä¸€è‡´")
        issues.append("å»ºè®®ä½¿ç”¨ç»Ÿä¸€çš„æ–‡æ¡£æ ¼å¼ï¼ˆGoogleé£æ ¼æˆ–NumPyé£æ ¼ï¼‰")
        
        return issues
    
    def generate_enhanced_report(self) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææŠ¥å‘Š"""
        tool_analysis = self.analyze_tool_documentation()
        core_analysis = self.analyze_core_modules()
        consistency_issues = self.check_documentation_consistency()
        
        report = []
        report.append("# ğŸ“‹ Pythoné¡¹ç›®æ–‡æ¡£è´¨é‡æ·±åº¦åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # å·¥å…·æ–‡æ¡£åˆ†æ
        report.append("## ğŸ”§ å·¥å…·æ–‡æ¡£åˆ†æ")
        report.append(f"- å·¥å…·ç±»æ€»æ•°: {len(tool_analysis['well_documented']) + len(tool_analysis['poorly_documented'])}")
        report.append(f"- æ–‡æ¡£åŒ–è‰¯å¥½çš„å·¥å…·: {len(tool_analysis['well_documented'])}")
        report.append(f"- æ–‡æ¡£ç¼ºå¤±çš„å·¥å…·: {len(tool_analysis['poorly_documented'])}")
        report.append(f"- æœ‰æè¿°æ–‡ä»¶çš„å·¥å…·: {len(tool_analysis['descriptions'])}")
        
        if tool_analysis['descriptions']:
            report.append("\n### ğŸ“„ å·¥å…·æè¿°æ–‡ä»¶")
            for tool_file, desc_file in tool_analysis['descriptions'].items():
                report.append(f"- {tool_file}: {desc_file}")
        
        report.append("")
        
        # æ ¸å¿ƒæ¨¡å—åˆ†æ
        report.append("## ğŸ¯ æ ¸å¿ƒæ¨¡å—æ–‡æ¡£åˆ†æ")
        for file_path, doc_info in core_analysis['documentation_level'].items():
            report.append(f"\n### {file_path}")
            report.append(f"- æ–‡æ¡£åŒ–ç‡: {doc_info['percentage']:.1f}% ({doc_info['documented']}/{doc_info['total']})")
            
            if doc_info['percentage'] < 50:
                report.append("- âš ï¸ æ–‡æ¡£åŒ–ç¨‹åº¦è¾ƒä½ï¼Œéœ€è¦ä¼˜å…ˆæ”¹è¿›")
            elif doc_info['percentage'] < 80:
                report.append("- âš¡ æ–‡æ¡£åŒ–ç¨‹åº¦ä¸­ç­‰ï¼Œå¯ä»¥è¿›ä¸€æ­¥å®Œå–„")
            else:
                report.append("- âœ… æ–‡æ¡£åŒ–ç¨‹åº¦è‰¯å¥½")
        
        report.append("")
        
        # å¤æ‚å‡½æ•°åˆ†æ
        if core_analysis['complex_functions']:
            report.append("## ğŸ” å¤æ‚å‡½æ•°æ–‡æ¡£åˆ†æ")
            report.append(f"å‘ç° {len(core_analysis['complex_functions'])} ä¸ªå‚æ•°è¾ƒå¤šçš„å¤æ‚å‡½æ•°")
            
            missing_doc_complex = [f for f in core_analysis['complex_functions'] if not f['has_doc']]
            if missing_doc_complex:
                report.append(f"\nå…¶ä¸­ {len(missing_doc_complex)} ä¸ªç¼ºå°‘æ–‡æ¡£:")
                for func in missing_doc_complex[:5]:
                    report.append(f"- {func['file']}::{func['function']} ({func['params']}ä¸ªå‚æ•°)")
        
        report.append("")
        
        # ä¸€è‡´æ€§é—®é¢˜
        report.append("## ğŸ¨ æ–‡æ¡£æ ¼å¼ä¸€è‡´æ€§åˆ†æ")
        for issue in consistency_issues:
            report.append(f"- {issue}")
        
        report.append("")
        
        # å…·ä½“æ”¹è¿›å»ºè®®
        report.append("## ğŸš€ å…·ä½“æ”¹è¿›å»ºè®®")
        report.append("")
        report.append("### ğŸ”¥ ç´§æ€¥æ”¹è¿›ï¼ˆç«‹å³å¤„ç†ï¼‰")
        report.append("1. **æ ¸å¿ƒå·¥å…·ç±»æ–‡æ¡£åŒ–**: ä¸ºæ‰€æœ‰å·¥å…·ç±»æ·»åŠ å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²")
        report.append("2. **å¤æ‚å‡½æ•°ä¼˜å…ˆ**: ä¼˜å…ˆä¸ºå‚æ•°è¾ƒå¤šã€é€»è¾‘å¤æ‚çš„å‡½æ•°æ·»åŠ æ–‡æ¡£")
        report.append("3. **APIæ–‡æ¡£æ ‡å‡†åŒ–**: ç»Ÿä¸€ä½¿ç”¨Googleé£æ ¼æ–‡æ¡£æ ¼å¼")
        report.append("")
        report.append("### âš¡ é‡è¦æ”¹è¿›ï¼ˆè¿‘æœŸå®Œæˆï¼‰")
        report.append("1. **æ¨¡å—çº§æ–‡æ¡£**: ä¸ºæ¯ä¸ªæ¨¡å—æ·»åŠ æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¯´æ˜æ¨¡å—ç”¨é€”")
        report.append("2. **å‚æ•°å®Œæ•´æ€§**: æ‰€æœ‰å‡½æ•°æ–‡æ¡£éƒ½åº”åŒ…å«å‚æ•°è¯´æ˜å’Œè¿”å›å€¼è¯´æ˜")
        report.append("3. **å¼‚å¸¸è¯´æ˜**: åœ¨æ–‡æ¡£ä¸­æ·»åŠ å¯èƒ½æŠ›å‡ºçš„å¼‚å¸¸è¯´æ˜")
        report.append("")
        report.append("### ğŸ“ ä¼˜åŒ–æ”¹è¿›ï¼ˆæŒç»­è¿›è¡Œï¼‰")
        report.append("1. **ç¤ºä¾‹ä»£ç **: åœ¨æ–‡æ¡£ä¸­æ·»åŠ ä½¿ç”¨ç¤ºä¾‹")
        report.append("2. **ç‰ˆæœ¬ä¿¡æ¯**: è®°å½•APIçš„ç‰ˆæœ¬å’Œå˜æ›´å†å²")
        report.append("3. **æ€§èƒ½è¯´æ˜**: å¯¹æ€§èƒ½å…³é”®çš„å‡½æ•°æ·»åŠ æ€§èƒ½è¯´æ˜")
        report.append("")
        
        # æœ€ä½³å®è·µå»ºè®®
        report.append("## ğŸ’ æ–‡æ¡£æœ€ä½³å®è·µå»ºè®®")
        report.append("")
        report.append("### æ–‡æ¡£å­—ç¬¦ä¸²ç»“æ„ï¼ˆGoogleé£æ ¼ï¼‰")
        report.append("""
def function_name(param1: type, param2: type) -> return_type:
    \"\"\"ä¸€è¡Œç®€æ´çš„å‡½æ•°åŠŸèƒ½æè¿°ã€‚
    
    æ›´è¯¦ç»†çš„åŠŸèƒ½æè¿°ï¼ŒåŒ…æ‹¬ä½¿ç”¨åœºæ™¯å’Œæ³¨æ„äº‹é¡¹ã€‚
    
    Args:
        param1: ç¬¬ä¸€ä¸ªå‚æ•°çš„æè¿°ã€‚
        param2: ç¬¬äºŒä¸ªå‚æ•°çš„æè¿°ã€‚
        
    Returns:
        è¿”å›å€¼çš„è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬ç±»å‹å’Œå«ä¹‰ã€‚
        
    Raises:
        ValueError: å½“å‚æ•°æ— æ•ˆæ—¶æŠ›å‡ºã€‚
        
    Example:
        >>> function_name("value1", "value2")
        "expected_result"
    \"\"\"
""")
        
        report.append("### ç±»æ–‡æ¡£å­—ç¬¦ä¸²ç»“æ„")
        report.append("""
class ClassName:
    \"\"\"ä¸€è¡Œç®€æ´çš„ç±»åŠŸèƒ½æè¿°ã€‚
    
    æ›´è¯¦ç»†çš„ç±»æè¿°ï¼ŒåŒ…æ‹¬ä¸»è¦èŒè´£å’Œä½¿ç”¨æ–¹å¼ã€‚
    
    Attributes:
        attr1: å±æ€§çš„æè¿°ã€‚
        attr2: å±æ€§çš„æè¿°ã€‚
        
    Example:
        >>> instance = ClassName(param1, param2)
        >>> instance.method_name()
    \"\"\"
""")
        
        return '\n'.join(report)


if __name__ == '__main__':
    analyzer = DocQualityAnalyzer('/home/mt/code/py/kimi-cli/doc_analysis_results.json')
    report = analyzer.generate_enhanced_report()
    
    with open('/home/mt/code/py/kimi-cli/doc_quality_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(report)
    print("\n" + "="*60)
    print("æ·±åº¦åˆ†æå®Œæˆï¼è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° doc_quality_report.md")