#!/usr/bin/env python3
"""
æ–‡æ¡£åˆ†æå·¥å…· - åˆ†æPythoné¡¹ç›®çš„æ–‡æ¡£å®Œæ•´æ€§å’Œè´¨é‡
"""

import ast
import os
from pathlib import Path
from typing import Dict, List, Tuple, Set
import json
from collections import defaultdict


class DocAnalyzer:
    """Pythonæ–‡æ¡£åˆ†æå™¨"""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.results = {
            'total_files': 0,
            'total_functions': 0,
            'total_classes': 0,
            'doc_coverage': {
                'modules': 0,
                'functions': 0,
                'classes': 0,
                'methods': 0
            },
            'detailed_results': [],
            'missing_docs': [],
            'quality_issues': []
        }
    
    def analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶çš„æ–‡æ¡£æƒ…å†µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            file_result = {
                'file_path': str(file_path.relative_to(self.project_path)),
                'module_doc': bool(ast.get_docstring(tree)),
                'functions': [],
                'classes': [],
                'missing_docs': [],
                'quality_issues': []
            }
            
            # åˆ†ææ¨¡å—çº§æ–‡æ¡£
            if not file_result['module_doc']:
                file_result['missing_docs'].append(('module', file_path.name))
            
            # åˆ†æå‡½æ•°å’Œç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    self._analyze_function(node, file_result, file_path)
                elif isinstance(node, ast.ClassDef):
                    self._analyze_class(node, file_result, file_path)
            
            return file_result
            
        except Exception as e:
            return {
                'file_path': str(file_path.relative_to(self.project_path)),
                'error': str(e)
            }
    
    def _analyze_function(self, node: ast.FunctionDef, file_result: Dict, file_path: Path):
        """åˆ†æå‡½æ•°çš„æ–‡æ¡£æƒ…å†µ"""
        func_info = {
            'name': node.name,
            'has_docstring': bool(ast.get_docstring(node)),
            'is_method': False,
            'line_number': node.lineno,
            'params': [arg.arg for arg in node.args.args],
            'returns': bool(node.returns)
        }
        
        file_result['functions'].append(func_info)
        
        if not func_info['has_docstring']:
            file_result['missing_docs'].append(
                ('function', f"{node.name} (line {node.lineno})")
            )
        else:
            # æ£€æŸ¥æ–‡æ¡£è´¨é‡
            docstring = ast.get_docstring(node)
            quality_issues = self._check_docstring_quality(docstring, node.name, 'function')
            file_result['quality_issues'].extend(quality_issues)
    
    def _analyze_class(self, node: ast.ClassDef, file_result: Dict, file_path: Path):
        """åˆ†æç±»çš„æ–‡æ¡£æƒ…å†µ"""
        class_info = {
            'name': node.name,
            'has_docstring': bool(ast.get_docstring(node)),
            'line_number': node.lineno,
            'methods': [],
            'bases': [base.id if hasattr(base, 'id') else str(ast.dump(base)) 
                     for base in node.bases]
        }
        
        # åˆ†æç±»çš„æ–¹æ³•
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                method_info = {
                    'name': item.name,
                    'has_docstring': bool(ast.get_docstring(item)),
                    'line_number': item.lineno,
                    'params': [arg.arg for arg in item.args.args]
                }
                class_info['methods'].append(method_info)
                
                if not method_info['has_docstring']:
                    file_result['missing_docs'].append(
                        ('method', f"{node.name}.{item.name} (line {item.lineno})")
                    )
        
        file_result['classes'].append(class_info)
        
        if not class_info['has_docstring']:
            file_result['missing_docs'].append(
                ('class', f"{node.name} (line {node.lineno})")
            )
        else:
            # æ£€æŸ¥ç±»æ–‡æ¡£è´¨é‡
            docstring = ast.get_docstring(node)
            quality_issues = self._check_docstring_quality(docstring, node.name, 'class')
            file_result['quality_issues'].extend(quality_issues)
    
    def _check_docstring_quality(self, docstring: str, name: str, doc_type: str) -> List[str]:
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²çš„è´¨é‡"""
        issues = []
        
        if not docstring:
            return issues
        
        # æ£€æŸ¥é•¿åº¦
        if len(docstring.strip()) < 10:
            issues.append(f"{doc_type.title()} '{name}' çš„æ–‡æ¡£å­—ç¬¦ä¸²å¤ªçŸ­ (å°‘äº10ä¸ªå­—ç¬¦)")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å‚æ•°è¯´æ˜ï¼ˆå¯¹äºå‡½æ•°å’Œæ–¹æ³•ï¼‰
        if doc_type in ['function', 'method']:
            if 'Args:' not in docstring and 'å‚æ•°' not in docstring:
                issues.append(f"{doc_type.title()} '{name}' çš„æ–‡æ¡£ç¼ºå°‘å‚æ•°è¯´æ˜")
            
            if 'Returns:' not in docstring and 'è¿”å›' not in docstring:
                issues.append(f"{doc_type.title()} '{name}' çš„æ–‡æ¡£ç¼ºå°‘è¿”å›å€¼è¯´æ˜")
        
        # æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§
        lines = docstring.strip().split('\n')
        if len(lines) > 1:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸‰é‡å¼•å·
            if not docstring.startswith('"""') or not docstring.endswith('"""'):
                issues.append(f"{doc_type.title()} '{name}' çš„æ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼ä¸è§„èŒƒ")
        
        return issues
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„æ–‡æ¡£åˆ†æ"""
        python_files = list(self.project_path.rglob('*.py'))
        self.results['total_files'] = len(python_files)
        
        for file_path in python_files:
            if 'venv' in str(file_path) or '__pycache__' in str(file_path):
                continue
                
            file_result = self.analyze_file(file_path)
            self.results['detailed_results'].append(file_result)
            
            # ç»Ÿè®¡æ€»æ•°
            if 'error' not in file_result:
                self.results['total_functions'] += len(file_result['functions'])
                self.results['total_classes'] += len(file_result['classes'])
                
                # ç»Ÿè®¡æ–‡æ¡£è¦†ç›–ç‡
                if file_result['module_doc']:
                    self.results['doc_coverage']['modules'] += 1
                
                for func in file_result['functions']:
                    if func['has_docstring']:
                        self.results['doc_coverage']['functions'] += 1
                
                for cls in file_result['classes']:
                    if cls['has_docstring']:
                        self.results['doc_coverage']['classes'] += 1
                    
                    for method in cls['methods']:
                        if method['has_docstring']:
                            self.results['doc_coverage']['methods'] += 1
                
                # æ”¶é›†ç¼ºå¤±æ–‡æ¡£å’Œè´¨é‡é—®é¢˜çš„è¯¦ç»†ä¿¡æ¯
                for missing in file_result['missing_docs']:
                    self.results['missing_docs'].append({
                        'file': file_result['file_path'],
                        'type': missing[0],
                        'name': missing[1]
                    })
                
                for issue in file_result['quality_issues']:
                    self.results['quality_issues'].append({
                        'file': file_result['file_path'],
                        'issue': issue
                    })
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("# Pythoné¡¹ç›®æ–‡æ¡£å®Œæ•´æ€§åˆ†ææŠ¥å‘Š")
        report.append("=" * 50)
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("## ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        report.append(f"- æ€»æ–‡ä»¶æ•°: {self.results['total_files']}")
        report.append(f"- æ€»å‡½æ•°æ•°: {self.results['total_functions']}")
        report.append(f"- æ€»ç±»æ•°: {self.results['total_classes']}")
        report.append("")
        
        # æ–‡æ¡£è¦†ç›–ç‡
        report.append("## ğŸ“ˆ æ–‡æ¡£è¦†ç›–ç‡")
        
        if self.results['total_files'] > 0:
            module_coverage = (self.results['doc_coverage']['modules'] / self.results['total_files']) * 100
            report.append(f"- æ¨¡å—æ–‡æ¡£è¦†ç›–ç‡: {module_coverage:.1f}% ({self.results['doc_coverage']['modules']}/{self.results['total_files']})")
        
        if self.results['total_functions'] > 0:
            func_coverage = (self.results['doc_coverage']['functions'] / self.results['total_functions']) * 100
            report.append(f"- å‡½æ•°æ–‡æ¡£è¦†ç›–ç‡: {func_coverage:.1f}% ({self.results['doc_coverage']['functions']}/{self.results['total_functions']})")
        
        if self.results['total_classes'] > 0:
            class_coverage = (self.results['doc_coverage']['classes'] / self.results['total_classes']) * 100
            report.append(f"- ç±»æ–‡æ¡£è¦†ç›–ç‡: {class_coverage:.1f}% ({self.results['doc_coverage']['classes']}/{self.results['total_classes']})")
        
        # æ–¹æ³•è¦†ç›–ç‡éœ€è¦å•ç‹¬è®¡ç®—
        total_methods = sum(len(cls.get('methods', [])) 
                           for file_result in self.results['detailed_results'] 
                           for cls in file_result.get('classes', []))
        
        if total_methods > 0:
            method_coverage = (self.results['doc_coverage']['methods'] / total_methods) * 100
            report.append(f"- æ–¹æ³•æ–‡æ¡£è¦†ç›–ç‡: {method_coverage:.1f}% ({self.results['doc_coverage']['methods']}/{total_methods})")
        
        report.append("")
        
        # å…³é”®ç¼ºå¤±æ–‡æ¡£
        report.append("## ğŸš¨ å…³é”®ç¼ºå¤±æ–‡æ¡£")
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„æ˜¾ç¤ºç¼ºå¤±æ–‡æ¡£
        missing_by_file = defaultdict(list)
        for missing in self.results['missing_docs']:
            missing_by_file[missing['file']].append(missing)
        
        for file_path, missing_items in missing_by_file.items():
            if len(missing_items) > 3:  # åªæ˜¾ç¤ºç¼ºå¤±è¾ƒå¤šçš„æ–‡ä»¶
                report.append(f"\n### {file_path}")
                for item in missing_items[:5]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    report.append(f"- {item['type']}: {item['name']}")
                if len(missing_items) > 5:
                    report.append(f"- ... è¿˜æœ‰ {len(missing_items) - 5} ä¸ªç¼ºå¤±é¡¹")
        
        report.append("")
        
        # æ–‡æ¡£è´¨é‡é—®é¢˜
        if self.results['quality_issues']:
            report.append("## âš ï¸ æ–‡æ¡£è´¨é‡é—®é¢˜")
            
            # æŒ‰é—®é¢˜ç±»å‹åˆ†ç»„
            issues_by_type = defaultdict(list)
            for issue in self.results['quality_issues']:
                issue_type = issue['issue'].split(':')[0].split(' ')[-1]
                issues_by_type[issue_type].append(issue)
            
            for issue_type, issues in issues_by_type.items():
                report.append(f"\n### {issue_type} ç›¸å…³é—®é¢˜ ({len(issues)}ä¸ª)")
                for issue in issues[:3]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    report.append(f"- {issue['file']}: {issue['issue']}")
                if len(issues) > 3:
                    report.append(f"- ... è¿˜æœ‰ {len(issues) - 3} ä¸ªç±»ä¼¼é—®é¢˜")
        
        report.append("")
        
        # æ”¹è¿›å»ºè®®
        report.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
        report.append("")
        report.append("### é«˜ä¼˜å…ˆçº§")
        report.append("1. **æ ¸å¿ƒæ¨¡å—æ–‡æ¡£åŒ–**: ä¸ºä¸»è¦çš„å·¥å…·ç±»å’Œæ ¸å¿ƒç®—æ³•æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²")
        report.append("2. **APIæ–‡æ¡£å®Œå–„**: æ‰€æœ‰å…¬å…±å‡½æ•°å’Œç±»éƒ½åº”è¯¥æœ‰æ¸…æ™°çš„æ–‡æ¡£è¯´æ˜")
        report.append("3. **å‚æ•°å’Œè¿”å›å€¼è¯´æ˜**: å‡½æ•°æ–‡æ¡£åº”åŒ…å«å‚æ•°è¯´æ˜å’Œè¿”å›å€¼è¯´æ˜")
        report.append("")
        report.append("### ä¸­ä¼˜å…ˆçº§")
        report.append("1. **æ¨¡å—çº§æ–‡æ¡£**: ä¸ºæ¯ä¸ªPythonæ¨¡å—æ·»åŠ æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²")
        report.append("2. **å¤æ‚é€»è¾‘æ³¨é‡Š**: ä¸ºç®—æ³•å®ç°æ·»åŠ è¯¦ç»†çš„è¡Œå†…æ³¨é‡Š")
        report.append("3. **ç¤ºä¾‹ä»£ç **: åœ¨æ–‡æ¡£ä¸­æ·»åŠ ä½¿ç”¨ç¤ºä¾‹")
        report.append("")
        report.append("### ä½ä¼˜å…ˆçº§")
        report.append("1. **æ–‡æ¡£æ ¼å¼ç»Ÿä¸€**: ç»Ÿä¸€ä½¿ç”¨Googleé£æ ¼æˆ–NumPyé£æ ¼çš„æ–‡æ¡£æ ¼å¼")
        report.append("2. **ç±»å‹æç¤ºæ–‡æ¡£**: ç»“åˆç±»å‹æç¤ºæä¾›æ›´å®Œæ•´çš„æ–‡æ¡£")
        report.append("3. **ç‰ˆæœ¬ä¿¡æ¯**: åœ¨æ–‡æ¡£ä¸­æ·»åŠ ç‰ˆæœ¬å’Œå˜æ›´ä¿¡æ¯")
        
        return '\n'.join(report)


if __name__ == '__main__':
    # è¿è¡Œåˆ†æ
    analyzer = DocAnalyzer('/home/mt/code/py/kimi-cli/src')
    analyzer.run_analysis()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()
    print(report)
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
    with open('/home/mt/code/py/kimi-cli/doc_analysis_results.json', 'w', encoding='utf-8') as f:
        json.dump(analyzer.results, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*50)
    print("åˆ†æå®Œæˆï¼è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° doc_analysis_results.json")